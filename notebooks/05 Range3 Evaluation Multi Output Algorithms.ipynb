{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data_3_range.csv\", header=None, names=[\"secenek\", \"cinsiyet\", \"sidmalzememarka\", \"UrunGrubu\", \"ResimAdresi\", \"YakaTipi\", \n",
    "                                                            \"CepOzelligi\", \"KolBoyuAciklama\", \"resimSira\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_img = data[[\"secenek\",\"ResimAdresi\", \"YakaTipi\", \"CepOzelligi\", \"KolBoyuAciklama\"]]\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_img.iloc[:, :2],\n",
    "    data_img.iloc[:, 2:],\n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_test.drop(index=[898, 745, 945], inplace=True) \n",
    "y_test.drop(index=[898, 745, 945], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "X_train[\"paths\"] = X_train.index.copy() \n",
    "X_train[\"paths\"] = X_train[\"paths\"].apply(lambda x: os.path.join(\"../data/range_3_images_AYD/train/\",str(x) + '.png')) \n",
    "\n",
    "X_test[\"paths\"] = X_test.index.copy() \n",
    "X_test[\"paths\"] = X_test[\"paths\"].apply(lambda x: os.path.join(\"../data/range_3_images_AYD/test/\",str(x) + '.png')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>YakaTipi_id</th>\n",
       "      <th>CepOzelligi_id</th>\n",
       "      <th>KolBoyuAciklama_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>../data/range_3_images_AYD/test/2399.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>../data/range_3_images_AYD/test/801.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>../data/range_3_images_AYD/test/2289.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>../data/range_3_images_AYD/test/2345.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>../data/range_3_images_AYD/test/3616.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paths  YakaTipi_id  CepOzelligi_id  \\\n",
       "2399  ../data/range_3_images_AYD/test/2399.png            0               0   \n",
       "801    ../data/range_3_images_AYD/test/801.png            0               0   \n",
       "2289  ../data/range_3_images_AYD/test/2289.png            1               0   \n",
       "2345  ../data/range_3_images_AYD/test/2345.png            0               0   \n",
       "3616  ../data/range_3_images_AYD/test/3616.png            3               0   \n",
       "\n",
       "      KolBoyuAciklama_id  \n",
       "2399                   1  \n",
       "801                    0  \n",
       "2289                   0  \n",
       "2345                   0  \n",
       "3616                   1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaka_id = pd.Series(y_train.YakaTipi.value_counts().index).to_dict()  \n",
    "cep_id = pd.Series(y_train.CepOzelligi.value_counts().index).to_dict()   \n",
    "kolBoyu_id = pd.Series(y_train.KolBoyuAciklama.value_counts().index).to_dict()   \n",
    "\n",
    "yaka_id = {v: k for k, v in yaka_id.items()}\n",
    "cep_id = {v: k for k, v in cep_id.items()}\n",
    "kolBoyu_id = {v: k for k, v in kolBoyu_id.items()}\n",
    "\n",
    "y_train['YakaTipi_id'] = y_train['YakaTipi'].map(yaka_id)\n",
    "y_train['CepOzelligi_id'] = y_train['CepOzelligi'].map(cep_id)\n",
    "y_train['KolBoyuAciklama_id'] = y_train['KolBoyuAciklama'].map(kolBoyu_id)\n",
    "\n",
    "y_test['YakaTipi_id'] = y_test['YakaTipi'].map(yaka_id)\n",
    "y_test['CepOzelligi_id'] = y_test['CepOzelligi'].map(cep_id)\n",
    "y_test['KolBoyuAciklama_id'] = y_test['KolBoyuAciklama'].map(kolBoyu_id)\n",
    "\n",
    "Xy_train = pd.concat([X_train, y_train], axis=1).drop(columns=[\"secenek\", \"ResimAdresi\", \"YakaTipi\", \"CepOzelligi\", \"KolBoyuAciklama\"])\n",
    "Xy_test = pd.concat([X_test, y_test], axis=1).drop(columns=[\"secenek\", \"ResimAdresi\", \"YakaTipi\", \"CepOzelligi\", \"KolBoyuAciklama\"]) \n",
    "Xy_test.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_data_generator import AydFashionDataGenerator\n",
    "custom_data_gen = AydFashionDataGenerator(Xy_train, Xy_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = custom_data_gen.generate_images(True, bathc_size=32, epoch=1)\n",
    "test_set = custom_data_gen.generate_images(False, bathc_size=32, epoch=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: VGG-16 Multi Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.models.load_model(\"../trained_models/model_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 170s 5s/step - loss: 1.1883 - YakaTipi_loss: 0.4441 - CepOzelligi_loss: 0.5691 - KolBoyuAciklama_loss: 0.1750 - YakaTipi_precision_yakaTipi: 0.8607 - YakaTipi_recall_yakaTipi: 0.8384 - CepOzelligi_precision_cep: 0.8057 - CepOzelligi_recall_cep: 0.7848 - KolBoyuAciklama_precision_kol: 0.8471 - KolBoyuAciklama_recall_kol: 0.8402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1882787942886353,\n",
       " 0.4440896213054657,\n",
       " 0.5691457986831665,\n",
       " 0.17504343390464783,\n",
       " 0.8606782555580139,\n",
       " 0.8383928537368774,\n",
       " 0.8056828379631042,\n",
       " 0.7848214507102966,\n",
       " 0.8471074104309082,\n",
       " 0.8401639461517334]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(paths: list, model: tf.keras.models.Model, dims: tuple = (224, 224, 3)):\n",
    "    \"\"\"\n",
    "    model: model which you want to predict with   \n",
    "    path: paths of the images \n",
    "    dims: default dim of the image \n",
    "    \"\"\" \n",
    "    result = dict()   \n",
    "    for cls_n in model.outputs:\n",
    "        result[cls_n.name] = [] \n",
    "        \n",
    "    i = 0 \n",
    "    for path in paths:\n",
    "        img = tf.io.read_file(path) \n",
    "        img = tf.image.decode_jpeg(img, channels=3) \n",
    "        img = tf.image.resize(img, [dims[0], dims[1]]) \n",
    "        img = tf.reshape(img, [1, dims[0], dims[1], dims[2]])\n",
    "\n",
    "        d = 0 \n",
    "        y_hat = model.predict(img, verbose=0)\n",
    "        for key in result.keys():\n",
    "            result[key].append(y_hat[d].squeeze().tolist())\n",
    "            d += 1 \n",
    "            \n",
    "        # result.append(model.predict(img, verbose=0)) \n",
    "        i = i + 1 \n",
    "        if i % 100 == 0: \n",
    "            print(f\"{i} th iteration. You have {len(paths)} inputs. \")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_dic = predict(X_test[\"paths\"].to_list()[:5], \n",
    "        model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_id_to_one_hot(y_test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        y_test: it has to consist of just ids of outputs\n",
    "        \n",
    "        return list of one hot dummies for each output\n",
    "    \"\"\"\n",
    "    result = dict() \n",
    "    for col in y_test: \n",
    "        result[col] = pd.get_dummies(y_test[col]).to_numpy().tolist() \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = y_id_to_one_hot(y_test.iloc[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score \n",
    "\n",
    "class MultiOutputModelTester:\n",
    "    def __init__(self, model: tf.keras.models.Model, y_test: pd.DataFrame, paths: list, dims: tuple = (224, 224, 3)): \n",
    "        \"\"\"\n",
    "            model: model which you want to predict with   \n",
    "            paths: paths of the images \n",
    "            dims: default dim of the image \n",
    "            y_test: actual results. it has to consist of just ids of outputs and order is important. it must be same with the order of \n",
    "                    models outputs layers. \n",
    "        \"\"\"\n",
    "        self.model = model \n",
    "        self.y_test = y_test \n",
    "        self.paths = paths \n",
    "        self.dims = dims\n",
    "\n",
    "        self.ys = dict()\n",
    "        self.y_hats = dict() \n",
    "\n",
    "        for col in y_test: \n",
    "                self.ys[col] = []\n",
    "                self.y_hats[col] = [] \n",
    "        \n",
    "        self._predict(self.paths, self.model, self.dims) # to fill y_hats\n",
    "        self._y_id_to_one_hot(self.y_test) #to fill ys \n",
    "        \n",
    "    def _predict(self, paths: list, model: tf.keras.models.Model, dims: tuple = (224, 224, 3)):\n",
    "        result = dict()   \n",
    "        i = 0 \n",
    "        for path in paths:\n",
    "            img = tf.io.read_file(path) \n",
    "            img = tf.image.decode_jpeg(img, channels=3) \n",
    "            img = tf.image.resize(img, [dims[0], dims[1]]) \n",
    "            img = tf.reshape(img, [1, dims[0], dims[1], dims[2]])\n",
    "\n",
    "            d = 0 \n",
    "            y_hat = model.predict(img, verbose=0)\n",
    "            for key in self.y_hats.keys():\n",
    "                self.y_hats[key].append(y_hat[d].squeeze().tolist())\n",
    "                d += 1 \n",
    "                    \n",
    "            i = i + 1 \n",
    "            if i % 100 == 0: \n",
    "                print(f\"{i} th iteration. You have {len(paths)} inputs. \")\n",
    "        \n",
    "    def _y_id_to_one_hot(self, y_test: pd.DataFrame):\n",
    "        \"\"\"           \n",
    "            return list of one hot dummies for each output\n",
    "        \"\"\"\n",
    "        result = dict() \n",
    "        for col in y_test: \n",
    "            self.ys[col] = pd.get_dummies(y_test[col]).to_numpy().tolist()                 \n",
    "        \n",
    "    def get_recall(self, threshold=0.5):\n",
    "        result = dict() \n",
    "        for col in self.y_hats.keys(): \n",
    "            custom_yhats = np.array(self.y_hats[col].copy()) \n",
    "            if custom_yhats.ndim == 2:\n",
    "                zeros = np.zeros(custom_yhats.shape) \n",
    "                zeros[np.arange(custom_yhats.shape[0]), np.argmax(custom_yhats, axis=1)] = 1\n",
    "                custom_yhats = zeros \n",
    "            else:\n",
    "                custom_yhats[custom_yhats >= 0.5] = 1 \n",
    "                custom_yhats[custom_yhats < 0.5] = 0 \n",
    "\n",
    "            result[col] = {\n",
    "                \"threshold\": threshold, \n",
    "                \"precision_weighted\": round(precision_score(self.ys[col], zeros, average=\"weighted\"), 2),\n",
    "                \"recall_weighted\": round(recall_score(self.ys[col], zeros, average=\"weighted\"), 2), \n",
    "                \"f1_score_weighted\": round(f1_score(self.ys[col], zeros, average=\"weighted\"), 2)\n",
    "            }\n",
    "        return result\n",
    "\n",
    "    def get_precision():\n",
    "        return None \n",
    "    def get_f1Score():\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.zeros(f.shape) \n",
    "zeros[np.arange(f.shape[0]), np.argmax(f, axis=1)] = 1 \n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = MultiOutputModelTester(model_3, y_test.iloc[:5, 3:], X_test[\"paths\"].to_list()[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-label binary indicator input with different numbers of labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23960\\643364733.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23960\\567239460.py\u001b[0m in \u001b[0;36mget_recall\u001b[1;34m(self, threshold)\u001b[0m\n\u001b[0;32m     66\u001b[0m             result[col] = {\n\u001b[0;32m     67\u001b[0m                 \u001b[1;34m\"threshold\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[1;34m\"precision_weighted\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                 \u001b[1;34m\"recall_weighted\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;34m\"f1_score_weighted\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m     \"\"\"\n\u001b[1;32m-> 1757\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1758\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1759\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1351\u001b[1;33m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1352\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     ):\n\u001b[1;32m---> 94\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;34m\"Multi-label binary indicator input with different numbers of labels\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-label binary indicator input with different numbers of labels"
     ]
    }
   ],
   "source": [
    "d.get_recall() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-label binary indicator input with different numbers of labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23960\\1066524605.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcustom_yhats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcustom_yhats\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_yhats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m     \"\"\"\n\u001b[1;32m-> 1757\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1758\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1759\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1351\u001b[1;33m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1352\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\melih.kacaman\\Anaconda3\\envs\\env_similar-products\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     ):\n\u001b[1;32m---> 94\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;34m\"Multi-label binary indicator input with different numbers of labels\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-label binary indicator input with different numbers of labels"
     ]
    }
   ],
   "source": [
    "for col in d.y_hats.keys(): \n",
    "    custom_yhats = np.array(d.y_hats[col].copy()) \n",
    "    if custom_yhats.ndim == 2:\n",
    "                zeros = np.zeros(custom_yhats.shape) \n",
    "                zeros[np.arange(custom_yhats.shape[0]), np.argmax(custom_yhats, axis=1)] = 1\n",
    "                custom_yhats = zeros\n",
    "    else:\n",
    "        custom_yhats[custom_yhats >= 0.5] = 1 \n",
    "        custom_yhats[custom_yhats < 0.5] = 0 \n",
    "    \n",
    "    precision_score(d.ys[col], custom_yhats, average=\"weighted\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(d.y_hats[\"YakaTipi_id\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array(d.y_hats[\"YakaTipi_id\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_similar-products",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
